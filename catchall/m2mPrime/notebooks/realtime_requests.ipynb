{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOI Machine to Machine (M2M) Realtime Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "* Create a user account on ooinet.oceanobservatories.org\n",
    "* Log in\n",
    "* Navigate to the drop down menu screen in the top-right corner menu\n",
    "* Click on the \"User Profile\" element of the drop down.\n",
    "* Copy and save the following data from the user profile: API Username and API Token. The API Username is similar to “OOIAPI-QTULEV9STCAS55”. The API Token is similar to “YXP2Q2W4SOP”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify your username and token\n",
    "username = 'API Username'\n",
    "token = 'API Token'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will request pressure data from the Cabled Axial Base (RS03AXPS) - Shallow Profiler (SF03A) - CTD (2A-CTDPFA302) sensor.\n",
    "\n",
    "Reference Designator: RS03AXPS-SF03A-2A-CTDPFA302  \n",
    "Delivery Method: streamed  \n",
    "Stream: ctdpf_sbe43_sample  \n",
    "Parameter: seawater_pressure  \n",
    "\n",
    "A good resource for finding the information you will need to input below is the Data Team Portal at http://ooi.visualocean.net/. This resource allows you to identify the Reference Designator, Delivery Method, Stream, and Parameter, alongside english descriptions of the instruments and data products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify your inputs\n",
    "sub_site = 'RS03AXPS'\n",
    "platform = 'SF03A'\n",
    "instrument = '2A-CTDPFA302'\n",
    "delivery_method = 'streamed'\n",
    "stream = 'ctdpf_sbe43_sample'\n",
    "parameter = 'seawater_pressure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pprint\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the base url for the request that will be built using the inputs above.\n",
    "BASE_URL = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv/'\n",
    "\n",
    "# we use ThreadPoolExecutor because it has a method .done, which can be polled for \n",
    "# completed of the task executed on that thread.\n",
    "pool = ThreadPoolExecutor(1)\n",
    "\n",
    "# time stamps are returned in time since 1900, so we subtract 70 years from \n",
    "# the time output using the ntp_delta variable\n",
    "ntp_epoch = datetime.datetime(1900, 1, 1)\n",
    "unix_epoch = datetime.datetime(1970, 1, 1)\n",
    "ntp_delta = (unix_epoch - ntp_epoch).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert timestamps\n",
    "def ntp_seconds_to_datetime(ntp_seconds):\n",
    "    return datetime.datetime.utcfromtimestamp(ntp_seconds - ntp_delta).replace(microsecond=0)\n",
    "\n",
    "# send request on a thread\n",
    "def get_future_data(url, params, username, token):\n",
    "    auth = (username, token)\n",
    "    return pool.submit(requests.get, url, params=params, auth=auth)\n",
    "\n",
    "# parse response for timestamp and inform user if no new data returned\n",
    "def extract_keys(data, keys, min_time):\n",
    "    rdict = {key: [] for key in keys}\n",
    "    for record in data:\n",
    "        if record['time'] <= min_time:\n",
    "            time_r = record['time']\n",
    "            time_r = ntp_seconds_to_datetime(time_r)\n",
    "            time_r = time_r.strftime(\"%Y-%m-%d %H:%M:%S.000Z\")\n",
    "            print 'No new data found since ' + str(time_r) + '. Sending new request.'\n",
    "            continue\n",
    "        for key in keys:\n",
    "            rdict[key].append(record[key])\n",
    "    print 'Found %d new data points after filtering' % len(rdict['time'])\n",
    "    return rdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script is the main script. It will execute 10 requests, but if put into a while loop it can execute data requests indefinitely. See comments for explanations in line. The data response in json format contains all parameters under the input data stream, however, only prints out the values for the input parameter and corresponding timestamp. Note that the maximum points returned for a given time interval is 1000 points. Right now, the script sends a new request every 0.1 seconds, so you should never receive exceed 1000 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def requestNow(username, token, sub_site, platform, instrument, delivery_method, stream, parameter):\n",
    "    \n",
    "    # create the base url\n",
    "    request_url = '/'.join((BASE_URL, sub_site, platform, instrument, delivery_method, stream))\n",
    "    \n",
    "    # specify parameters which will be used in the get_future_data function. \n",
    "    # with each new request being sent, only the beginDT will change. \n",
    "    # it will be set to the time stamp of the last data point received. \n",
    "    # notice that there is no endDT specified, as a request with a beginDT \n",
    "    # and no endDT will return everything  from beginDT until present, \n",
    "    # up to 1000 data points.\n",
    "    params = {\n",
    "        'beginDT': None,\n",
    "        'limit': 1000,\n",
    "        'user': 'realtime',\n",
    "    }\n",
    "    \n",
    "    # start with the last 10 seconds of data from present time\n",
    "    begin_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=10)\n",
    "    \n",
    "    # last_time will be assigned as the time stamp of the last data point \n",
    "    # received once the first request is sent\n",
    "    last_time = 0\n",
    "    \n",
    "    for i in range(10): # replace with `while True:` to enter an endless data request loop\n",
    "        \n",
    "        # update beginDT for this request\n",
    "        begin_time_str = begin_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "        params['beginDT'] = begin_time_str\n",
    "\n",
    "        # send request in thread\n",
    "        data_future = get_future_data(request_url, params, username, token)\n",
    "        \n",
    "        # poll until complete\n",
    "        while not data_future.done:\n",
    "            # while request not complete, yield control to event loop\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        # request complete, if not 200, log error and try again\n",
    "        response = data_future.result()\n",
    "        if response.status_code != 200:\n",
    "            print 'Error fetching data', response.text\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "        \n",
    "        # store json response\n",
    "        data = response.json()\n",
    "        \n",
    "        # use extract_keys function to inform users about whether \n",
    "        # or not data is being returned. parse data in json response \n",
    "        # for input parameter and corresponding timestamp\n",
    "        data = extract_keys(data, ['time', parameter], min_time=last_time)\n",
    "\n",
    "        # if no data is returned, try again\n",
    "        if not data['time']:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        # set beginDT to time stamp of last data point returned\n",
    "        last_time = data['time'][-1]\n",
    "        begin_time = ntp_seconds_to_datetime(last_time)\n",
    "\n",
    "        # print data points returned\n",
    "        print \"\\n\"\n",
    "        pprint.pprint(data)\n",
    "        print \"\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 new data points after filtering\n",
      "\n",
      "\n",
      "{'seawater_pressure': [47.60514098321581,\n",
      "                       47.57840214897592,\n",
      "                       47.54951961970842,\n",
      "                       47.52705511931374,\n",
      "                       47.51635987781392,\n",
      "                       47.51956743670596],\n",
      " 'time': [3709549088.544247,\n",
      "          3709549089.5441523,\n",
      "          3709549090.543849,\n",
      "          3709549091.544589,\n",
      "          3709549092.5441813,\n",
      "          3709549093.543878]}\n",
      "\n",
      "\n",
      "No new data found since 2017-07-20 14:18:13.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n",
      "No new data found since 2017-07-20 14:18:13.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n",
      "No new data found since 2017-07-20 14:18:13.000Z. Sending new request.\n",
      "Found 5 new data points after filtering\n",
      "\n",
      "\n",
      "{'seawater_pressure': [47.53882003436634,\n",
      "                       47.567702548259355,\n",
      "                       47.59444283900374,\n",
      "                       47.61583335011346,\n",
      "                       47.62653293165725],\n",
      " 'time': [3709549094.5440984,\n",
      "          3709549095.543898,\n",
      "          3709549096.54422,\n",
      "          3709549097.544231,\n",
      "          3709549098.544865]}\n",
      "\n",
      "\n",
      "No new data found since 2017-07-20 14:18:18.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n",
      "No new data found since 2017-07-20 14:18:18.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n",
      "No new data found since 2017-07-20 14:18:18.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n",
      "No new data found since 2017-07-20 14:18:18.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n",
      "No new data found since 2017-07-20 14:18:18.000Z. Sending new request.\n",
      "Found 5 new data points after filtering\n",
      "\n",
      "\n",
      "{'seawater_pressure': [47.62332392196205,\n",
      "                       47.60728032274888,\n",
      "                       47.581609702221215,\n",
      "                       47.55807697411115,\n",
      "                       47.53775180965559],\n",
      " 'time': [3709549099.544249,\n",
      "          3709549100.5445724,\n",
      "          3709549101.5439563,\n",
      "          3709549102.5445924,\n",
      "          3709549103.544915]}\n",
      "\n",
      "\n",
      "No new data found since 2017-07-20 14:18:23.000Z. Sending new request.\n",
      "Found 0 new data points after filtering\n"
     ]
    }
   ],
   "source": [
    "requestNow(username, token, sub_site, platform, instrument, delivery_method, stream, parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
