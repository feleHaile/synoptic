{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io\n",
    "import obspy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import requests\n",
    "from soundfile import SoundFile\n",
    "from modest_image import imshow\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (25.0, 30.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://rawdata.oceanobservatories.org/files/CE02SHBP/LJ01D/11-HYDBBA106/2015/12/16/OO-HYEA2--YDH-2015-12-16T02:20:00.000000.mseed'\n",
    "# stream = obspy.read(url, ssl_verify=False)  # Fetch from data server\n",
    "stream = obspy.read(url)  # Read local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stft(data, fs, fft_size=1024, overlap_fac=.5):\n",
    "    # from https://kevinsprojects.wordpress.com/2014/12/13/short-time-fourier-transform-using-python-and-numpy/\n",
    "    # data = a numpy array containing the signal to be processed\n",
    "    # fs = a scalar which is the sampling frequency of the data\n",
    "\n",
    "    hop_size = np.int32(np.floor(fft_size * (1-overlap_fac)))\n",
    "    pad_end_size = fft_size          # the last segment can overlap the data by no more than one window size\n",
    "    total_segments = np.int32(np.ceil(len(data) / np.float32(hop_size)))\n",
    "    t_max = len(data) / np.float32(fs)\n",
    "\n",
    "    window = np.hanning(fft_size)  # our half cosine window\n",
    "    inner_pad = np.zeros(fft_size) # the zeros which will be used to double each segment size\n",
    "\n",
    "    proc = np.concatenate((data, np.zeros(pad_end_size)))              # the data to process\n",
    "    result = np.empty((total_segments, fft_size), dtype=np.float32)    # space to hold the result\n",
    "\n",
    "    for i in xrange(total_segments):                      # for each segment\n",
    "        current_hop = hop_size * i                        # figure out the current segment offset\n",
    "        segment = proc[current_hop:current_hop+fft_size]  # get the current segment\n",
    "        windowed = segment * window                       # multiply by the half cosine function\n",
    "        padded = np.append(windowed, inner_pad)           # add 0s to double the length of the data\n",
    "        spectrum = np.fft.fft(padded) / fft_size          # take the Fourier Transform and scale # samples\n",
    "        autopower = np.abs(spectrum * np.conj(spectrum))  # find the autopower spectrum\n",
    "        result[i, :] = autopower[:fft_size]               # append to the results array\n",
    "\n",
    "    result = 20*np.log10(result)          # scale to db\n",
    "    result = np.clip(result, -40, 200)    # clip values\n",
    "    return result\n",
    "\n",
    "def specgram(data):\n",
    "    X = stft(data, 64000)\n",
    "    vmin = np.nanpercentile(X, 5)\n",
    "    vmax = np.nanpercentile(X, 95)\n",
    "    num_plots = 10\n",
    "    fig, axes = plt.subplots(num_plots, sharex=False, sharey=True)\n",
    "    \n",
    "    x, y = X.shape\n",
    "    \n",
    "    yticks = np.linspace(0, y, 9)\n",
    "    yticklabels = np.round(np.linspace(0, 32000, 9)).astype(int)\n",
    "    \n",
    "    step = len(X)/num_plots\n",
    "    for index in range(num_plots):\n",
    "        start = index * step\n",
    "        stop = start + step\n",
    "        data_slice = X[start:stop]\n",
    "        ax = axes[index]\n",
    "        ax.set_ylabel('freq (Hz)')\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.set_yticklabels(yticklabels)\n",
    "        data_axes = plt.imshow(ax, data_slice.T, origin='lower', cmap='jet', interpolation='nearest',\n",
    "                     aspect='auto', vmin=vmin, vmax=vmax)\n",
    "\n",
    "    cax = fig.add_axes([0.965, 0.12, 0.01, 0.775])\n",
    "    cb = fig.colorbar(data_axes, cax=cax, use_gridspec=True)\n",
    "    cb.set_label('dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "specgram(stream[0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the DC component of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = stream.copy()\n",
    "filtered.filter('highpass', freq=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write as WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered.write('voices.wav', format='WAV', framerate=64000, width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.write('voices32.wav', format='WAV', framerate=64000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write as FLAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with SoundFile('test24.flac', 'w', 64000, 1, 'PCM_24') as f:\n",
    "     f.write(stream[0].data / ((2.0**23)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Write an amplified FLAC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered.normalize()\n",
    "with SoundFile('amped.flac', 'w', 64000, 1) as f:\n",
    "    f.write(filtered[0].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 OOI",
   "language": "python",
   "name": "ooi2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
