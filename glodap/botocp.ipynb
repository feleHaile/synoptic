{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "# boto copying from the AWS cloud\n",
    "\n",
    "### copying glodap data files from Amazon public cloud object storage to make local copies\n",
    "\n",
    "This notebook copies files from AWS S3 buckets to ```/home/jovyan/data```, i.e. the local Jupyter workspace.\n",
    "This *should not* be done when direct access to S3 is possible; but we are setting aside that aesthetic here.\n",
    "Copying from AWS object storage S3 buckets *should* in fact be done using **boto3**, which is distinct from\n",
    "its predecessor **boto**. However I don't have time to make that change at the moment; so we proceed with\n",
    "two lost style points using just plain **boto**.\n",
    "\n",
    "\n",
    "By the by Stack Overflow says:\n",
    "\n",
    "> The boto package is the hand-coded Python library that has been around \n",
    "since 2006. It is very popular and is fully supported by AWS but because \n",
    "it is hand-coded and there are so many services available (with more \n",
    "appearing all the time) it is difficult to maintain.\n",
    "> \n",
    "> So, boto3 is a new version of the boto library based on botocore. All \n",
    "of the low-level interfaces to AWS are driven from JSON service descriptions \n",
    "that are generated automatically from the canonical descriptions of the services. \n",
    "So, the interfaces are always correct and always up to date. There is a \n",
    "resource layer on top of the client-layer that provides a nicer, more Pythonic interface.\n",
    ">\n",
    ">The boto3 library is being actively developed by AWS and \\[is therefore recommended\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Don't run unless you want to grab glodap files from S3\n",
    "# This may take a couple minutes to run\n",
    "# It fails if ~/data/glodap does not exist; so it should really check for that and create it\n",
    "# The other key point here is that we should be using boto3\n",
    "\n",
    "import boto\n",
    "\n",
    "data_dir = '/home/jovyan/data/glodap/'\n",
    "local_salinity_filename = data_dir + 'glodap_salinity.nc'\n",
    "local_temperature_filename = data_dir + 'glodap_temperature.nc'\n",
    "local_oxygen_filename = data_dir + 'glodap_oxygen.nc'\n",
    "\n",
    "connection = boto.connect_s3(anon=True)\n",
    "bucket = connection.get_bucket('himatdata')\n",
    "for key in bucket.list():\n",
    "    keyname = str(key.name.encode('utf-8'))\n",
    "    if 'glodap/' in keyname and 'salinity' in keyname: key.get_contents_to_filename(local_salinity_filename)\n",
    "    elif 'glodap/' in keyname and 'temperature' in keyname: key.get_contents_to_filename(local_temperature_filename)\n",
    "    elif 'glodap/' in keyname and 'oxygen' in keyname: key.get_contents_to_filename(local_oxygen_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Don't run unless you want to grab a set of nine ARGO profile netcdf files (9 ARGO platforms (drifters (floats)))\n",
    "# f = ...strip strip strip strip is due to possible irregularities in the string cast of the key name\n",
    "# This may take a couple minutes to run\n",
    "\n",
    "import boto\n",
    "data_dir = '/home/jovyan/data/glodap/'\n",
    "connection = boto.connect_s3(anon=True)\n",
    "bucket = connection.get_bucket('himatdata')\n",
    "for key in bucket.list(): \n",
    "    keyname = str(key.name.encode('utf-8'))\n",
    "    f = keyname.strip(\"b'\").strip('b\"').strip('\"').strip(\"'\")\n",
    "    if 'argo-profiles' in keyname: \n",
    "        ff = '/home/jovyan/data/' + f\n",
    "        key.get_contents_to_filename(ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Don't run unless you want to grab a large (800MB) tar file from S3 bucket 'oceanhackweek' to the local directory\n",
    "# This contains a bunch of different sub-dirs and data files as it un-tars into the 'data' directory.\n",
    "# This takes less than a minute to run.\n",
    "\n",
    "import boto\n",
    "f = '/home/jovyan/data.tar'\n",
    "connection = boto.connect_s3(anon=True)\n",
    "bucket = connection.get_bucket('oceanhackweek')\n",
    "for key in bucket.list(): \n",
    "    keyname = str(key.name.encode('utf-8'))\n",
    "    if 'data.tar' in keyname: key.get_contents_to_filename(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
