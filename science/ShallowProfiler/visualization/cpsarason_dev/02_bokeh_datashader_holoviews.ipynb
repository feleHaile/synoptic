{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with large Cabled Array datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_uncabled = 'https://opendap.oceanobservatories.org/thredds/dodsC/ooi/michaesm-marine-rutgers/20170725T195526-CE06ISSM-RID16-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0006_CE06ISSM-RID16-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument.ncml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use xarray to open the dataset. Once the dataset is open, we are going to convert part of our dataset referred to as a DataArray into a Pandas Dataframe for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(url_uncabled, decode_times=True)\n",
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets select these two variables to plot\n",
    "x = 'time'\n",
    "y = 'pressure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = ds[y].to_dataframe()\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bokeh functions\n",
    "import os\n",
    "from bokeh.plotting import figure, output_file, reset_output, show, ColumnDataSource, save\n",
    "from bokeh.models import BoxAnnotation\n",
    "from bokeh.io import output_notebook # required to display Bokeh visualization in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        x=df1[x],\n",
    "        y=df1[y],\n",
    "    )\n",
    ")\n",
    "\n",
    "p = figure(width=600,\n",
    "           height=400,\n",
    "           title='CE06ISSM-RID16-03-CTDBPC000',\n",
    "           x_axis_label='Time (GMT)',\n",
    "           y_axis_label='Pressure (m)',\n",
    "           x_axis_type='datetime')\n",
    "\n",
    "p.line('x', 'y', line_width=3, source=source)\n",
    "p.circle('x', 'y', fill_color='white', size=4, source=source)\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks of normal plotting backends (Matplotlib, Bokeh, etc.)\n",
    "\n",
    "While Bokeh is a nice tool for interactive data visualization, it does not work very well with large datasets that number greater than tens of thousands of points. Most python plotting toolboxes have a limit to the amount of data they can plot, so the best approach to plotting these datasets in those toolboxes would be to downsample. However, downsampling is destructive and may cause us to miss out on important peaks or troughs in data. Since the Cabled Array data can have millions of points over a very small period of time, it's important to look at toolboxes that allow for non-destructive data visualization. \n",
    "\n",
    "Previously, we loaded a smaller CTD dataset from the Washington Inshore Surface Mooring (CE06ISSM). Now we are going to load a much larger dataset from the ASHES Vent Field. We will use xarray to utilize the lazy loading capability of dask and then plot the data with datashader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_cabled = 'https://opendap.oceanobservatories.org/thredds/dodsC/ooi/friedrich-knuth-rutgers/20180219T191719-RS03ASHS-MJ03B-10-CTDPFB304-streamed-ctdpf_optode_sample/deployment0003_RS03ASHS-MJ03B-10-CTDPFB304-streamed-ctdpf_optode_sample_20180205T190209.102547-20180219T190208.809978.nc'\n",
    "ds = xr.open_dataset(url_cabled, decode_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datashader does not handle datetimes very well so we loaded the netCDF file with xarray with the decode_times argument set equal to False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = ds[y].to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datashader\n",
    "\n",
    "With datashader, you can easily plot every data point for a given time series. Datashader utilizes the processing power of your computer in order to dynamically update the data as you zoom and pan. This allows for non-destructive data exploration \n",
    "\n",
    "This notebook makes use of this dynamic update capability but requires running a live Jupyter. If these plots are viewed statically by a Jupyter notebook viewer (such as on github) or are downloaded and not run on the server, the plots will not update when you zoom and pan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as dsp\n",
    "import datashader.transfer_functions as tf\n",
    "\n",
    "cvs = dsp.Canvas(plot_width=600, plot_height=400)\n",
    "agg = cvs.line(cdf, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.shade(agg)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the plot above, the results look the same as what you would get from any plotting program. However, you cannot easily resolve the peaks and troughs of the data just by looking.\n",
    "\n",
    "Next, let's use every 1000 points instead of plotting everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = 1000\n",
    "tf.shade(cvs.line(cdf[::sampling], 'time', 'pressure'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is similar to the one above, but you can see that points were removed compared to the previous graph. These points may have important information that we want to don't want to lose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holoviews\n",
    "The easiest way to use Datashader is via the HoloViews package. Holoviews allows you to easily generate both Datashader and non-Datashader plots with Matplotlib, Bokeh, or Plotly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import aggregate, datashade, dynspread, shade\n",
    "from holoviews.operation import decimate\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike datashader, HoloViews handles datetimes well. We will go ahead and convert the time integer from the ds into a datetime and save it as new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.decode_cf(ds)\n",
    "cdf2 = ds[y].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import DatetimeTickFormatter\n",
    "def apply_formatter(plot, element):\n",
    "    plot.handles['xaxis'].formatter = DatetimeTickFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%opts RGB [width=600]\n",
    "\n",
    "curve = hv.Curve((cdf2[x], cdf2[y]))\n",
    "curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts RGB [finalize_hooks=[apply_formatter] width=800]\n",
    "\n",
    "\n",
    "datashade(curve, cmap=[\"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoloViews also supplies some operations that are useful in combination with Datashader timeseries. For instance, you can compute a rolling mean of the results and then show a subset of outlier points, which will then support hover, selection, and other interactive Bokeh features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Overlay [finalize_hooks=[apply_formatter] width=800] \n",
    "%%opts Scatter [tools=['hover', 'box_select']] (line_color=\"black\" fill_color=\"red\" size=10)\n",
    "from holoviews.operation.timeseries import rolling, rolling_outlier_std\n",
    "smoothed = rolling(curve, rolling_window=50)\n",
    "outliers = rolling_outlier_std(curve, rolling_window=50, sigma=2)\n",
    "\n",
    "datashade(curve, cmap=[\"blue\"]) * dynspread(datashade(smoothed, cmap=[\"red\"]),max_px=1) * outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
